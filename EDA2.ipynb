{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Machine Learning with Lending Club Dataset - Oct 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 \n",
    "- Import needed libraries and load data into dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Lending Club dataset\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# give the path to the file \n",
    "path_to_file = \"./LoanStats_2017Q2.csv\"\n",
    "data = pd.read_csv(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105451 entries, 0 to 105450\n",
      "Columns: 137 entries, id to hardship_last_payment_amount\n",
      "dtypes: float64(60), int64(52), object(25)\n",
      "memory usage: 110.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 \n",
    "- Lets check all the columns with all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'member_id',\n",
       " 'url',\n",
       " 'desc',\n",
       " 'hardship_type',\n",
       " 'hardship_reason',\n",
       " 'hardship_status',\n",
       " 'deferral_term',\n",
       " 'hardship_amount',\n",
       " 'hardship_start_date',\n",
       " 'hardship_end_date',\n",
       " 'payment_plan_start_date',\n",
       " 'hardship_length',\n",
       " 'hardship_dpd',\n",
       " 'hardship_loan_status',\n",
       " 'orig_projected_additional_accrued_interest',\n",
       " 'hardship_payoff_balance_amount',\n",
       " 'hardship_last_payment_amount']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.isnull().all()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105451 entries, 0 to 105450\n",
      "Columns: 119 entries, loan_amnt to hardship_flag\n",
      "dtypes: float64(42), int64(52), object(25)\n",
      "memory usage: 95.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns with null or nan values\n",
    "df = data.dropna(axis=1, how='all')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hence, we dropped 137-119 = 18 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>...</th>\n",
       "      <th>sec_app_inq_last_6mths</th>\n",
       "      <th>sec_app_mort_acc</th>\n",
       "      <th>sec_app_open_acc</th>\n",
       "      <th>sec_app_revol_util</th>\n",
       "      <th>sec_app_open_il_6m</th>\n",
       "      <th>sec_app_num_rev_accts</th>\n",
       "      <th>sec_app_chargeoff_within_12_mths</th>\n",
       "      <th>sec_app_collections_12_mths_ex_med</th>\n",
       "      <th>sec_app_mths_since_last_major_derog</th>\n",
       "      <th>hardship_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.62%</td>\n",
       "      <td>360.95</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>14.08%</td>\n",
       "      <td>273.74</td>\n",
       "      <td>C</td>\n",
       "      <td>C3</td>\n",
       "      <td>Registered Nurse</td>\n",
       "      <td>9 years</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26000</td>\n",
       "      <td>26000</td>\n",
       "      <td>26000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.93%</td>\n",
       "      <td>838.10</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>7 years</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18950</td>\n",
       "      <td>18950</td>\n",
       "      <td>18950</td>\n",
       "      <td>60 months</td>\n",
       "      <td>21.45%</td>\n",
       "      <td>517.47</td>\n",
       "      <td>D</td>\n",
       "      <td>D5</td>\n",
       "      <td>QA Manager</td>\n",
       "      <td>1 year</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9600</td>\n",
       "      <td>9600</td>\n",
       "      <td>9600</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.97%</td>\n",
       "      <td>300.70</td>\n",
       "      <td>A</td>\n",
       "      <td>A5</td>\n",
       "      <td>Physician Assistant</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  funded_amnt_inv        term int_rate  installment  \\\n",
       "0      16000        16000            16000   60 months   12.62%       360.95   \n",
       "1       8000         8000             8000   36 months   14.08%       273.74   \n",
       "2      26000        26000            26000   36 months    9.93%       838.10   \n",
       "3      18950        18950            18950   60 months   21.45%       517.47   \n",
       "4       9600         9600             9600   36 months    7.97%       300.70   \n",
       "\n",
       "  grade sub_grade            emp_title emp_length      ...       \\\n",
       "0     C        C1              teacher  10+ years      ...        \n",
       "1     C        C3     Registered Nurse    9 years      ...        \n",
       "2     B        B2               Dealer    7 years      ...        \n",
       "3     D        D5           QA Manager     1 year      ...        \n",
       "4     A        A5  Physician Assistant   < 1 year      ...        \n",
       "\n",
       "  sec_app_inq_last_6mths  sec_app_mort_acc sec_app_open_acc  \\\n",
       "0                    NaN               NaN              NaN   \n",
       "1                    NaN               NaN              NaN   \n",
       "2                    NaN               NaN              NaN   \n",
       "3                    NaN               NaN              NaN   \n",
       "4                    NaN               NaN              NaN   \n",
       "\n",
       "  sec_app_revol_util sec_app_open_il_6m sec_app_num_rev_accts  \\\n",
       "0                NaN                NaN                   NaN   \n",
       "1                NaN                NaN                   NaN   \n",
       "2                NaN                NaN                   NaN   \n",
       "3                NaN                NaN                   NaN   \n",
       "4                NaN                NaN                   NaN   \n",
       "\n",
       "  sec_app_chargeoff_within_12_mths sec_app_collections_12_mths_ex_med  \\\n",
       "0                              NaN                                NaN   \n",
       "1                              NaN                                NaN   \n",
       "2                              NaN                                NaN   \n",
       "3                              NaN                                NaN   \n",
       "4                              NaN                                NaN   \n",
       "\n",
       "  sec_app_mths_since_last_major_derog hardship_flag  \n",
       "0                                 NaN             N  \n",
       "1                                 NaN             N  \n",
       "2                                 NaN             N  \n",
       "3                                 NaN             N  \n",
       "4                                 NaN             N  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "- feature selection and data exploration\n",
    "- Lets analyze each column data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line of code will convert interest rate column to float values. \n",
    "# As this will help us in our analysis and calculation.\n",
    "df.loc[:,'int_rate'] = df.loc[:,'int_rate'].str.replace('%', '').astype(float)\n",
    "df.int_rate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/generic.py:3660: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/generic.py:3924: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df.replace('n/a', np.nan,inplace=True)\n",
    "df['emp_length'].fillna(value=0,inplace=True)\n",
    "df['emp_length'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "df.emp_length = df.emp_length.astype(int)\n",
    "print(df['emp_length'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jun-2017    38087\n",
       "May-2017    37681\n",
       "Apr-2017    29683\n",
       "Name: issue_d, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.issue_d.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see above the column data type is int but values looks like string. Lets remove '-2017' from values and make this column as string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Jun    38087\n",
       "May    37681\n",
       "Apr    29683\n",
       "Name: issue_d, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'issue_d'] = df.loc[:,'issue_d'].str.replace('-2017', '')\n",
    "df.issue_d.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- earliest_cr_line (earliest credit line) column is important as this will tell us about the oldest creadit history. Also, this will help us t consider if someone is going to get retire or health issue. We will consider this for our analysis."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I need to correct/work on below part\n",
    "\n",
    "#from datetime import datetime\n",
    "#earliest_cr_line_dt = pd.to_datetime(df.earliest_cr_line.str)\n",
    "#print(df.earliest_cr_line.head())\n",
    "#dttoday = datetime.now().strftime('%Y-%m-%d')\n",
    "#df.dttoday =  dttoday\n",
    "#today_dt = pd.to_datetime(df.dttoday)\n",
    "#print(df.dttoday.head())\n",
    "#df['dateRange'] = \n",
    "#len(pd.date_range(earliest_cr_line_dt,today_dt,freq='M'))\n",
    "#df.dateRange.head()\n",
    "#df.loc[:,['dttoday','earliest_cr_line']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df.earliest_cr_line = pd.to_datetime(df.earliest_cr_line)\n",
    "\n",
    "dttoday = datetime.now().strftime('%Y-%m-%d')\n",
    "# There is a better way to do this. Need to check that.\n",
    "df.earliest_cr_line = df.earliest_cr_line.apply(lambda x: (\n",
    "        np.timedelta64((x - pd.Timestamp(dttoday)),'D').astype(int))/-365)\n",
    "df.earliest_cr_line = df.earliest_cr_line.astype(int)\n",
    "df.earliest_cr_line.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'revol_util'] = df.loc[:,'revol_util'].str.replace('%', '').astype(float)\n",
    "df.revol_util.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets do feature selection based on below 4 points. Some basic methods from a mathematics perspective:\n",
    "# feature selection based on Lecture Notes\n",
    "- Removing features with low variance\n",
    "- Univariate feature selection (using sklearn feature selection lib)\n",
    "- L1/L2-based feature selection (using Ridge, Lasso, ElasticNet regression {L1 penalty, L2 penalty})\n",
    "- Tree-based feature selection \n",
    "---------------------------------------\n",
    "- Grid Search CV (cross validation)\n",
    "- table plot - check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this analysis I want to create a model for predicting default loan amount based on available details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y = df.loan_amnt.values\n",
    "df.drop('loan_amnt',axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. trying low variance feature selection approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (105451, 118)\n",
      "Variation:\n",
      "{'acc_now_delinq': 284139524.63953346,\n",
      " 'acc_open_past_24mths': 55.475272620605544,\n",
      " 'addr_state': 10144209.478550678,\n",
      " 'all_util': 2.2658434230013116,\n",
      " 'annual_inc': 667.55732412557222,\n",
      " 'annual_inc_joint': 5.4370052297856013,\n",
      " 'application_type': 6.9391928103559524,\n",
      " 'avg_cur_bal': 22.509660174825676,\n",
      " 'bc_open_to_buy': 61.773485201802607,\n",
      " 'bc_util': 10.776977659126647,\n",
      " 'chargeoff_within_12_mths': 33.114736341821263,\n",
      " 'collection_recovery_fee': 1936387129.8600271,\n",
      " 'collections_12_mths_ex_med': 431.03235456616551,\n",
      " 'delinq_2yrs': 9699578.6348744594,\n",
      " 'delinq_amnt': 0.0010372468216211786,\n",
      " 'dti': 10138153.170837712,\n",
      " 'dti_joint': 10.408557642327631,\n",
      " 'earliest_cr_line': 171988.89744167883,\n",
      " 'emp_length': 0.65462840037453651,\n",
      " 'emp_title': 59.5548840649383,\n",
      " 'funded_amnt': 89847445.831444412,\n",
      " 'funded_amnt_inv': 89795989.339220271,\n",
      " 'grade': 200.09298527157966,\n",
      " 'home_ownership': 480.39909864090635,\n",
      " 'il_util': 1015.7348599671778,\n",
      " 'initial_list_status': 47.759727945467517,\n",
      " 'inq_fi': 11.675476681709098,\n",
      " 'inq_last_12m': 20.182424861313901,\n",
      " 'inq_last_6mths': 3.1133928116626555,\n",
      " 'installment': 4654011086.1249371,\n",
      " 'int_rate': 78502.885949720847,\n",
      " 'issue_d': 0.43282058901350623,\n",
      " 'last_credit_pull_d': 28359038.869333889,\n",
      " 'last_pymnt_amnt': 2.2889086017262597,\n",
      " 'last_pymnt_d': 593.27904695992913,\n",
      " 'loan_status': 527429542.30973011,\n",
      " 'max_bal_bc': 493.16612111856364,\n",
      " 'mo_sin_old_il_acct': 0.0035157896100597519,\n",
      " 'mo_sin_old_rev_tl_op': 0.31085042799786106,\n",
      " 'mo_sin_rcnt_rev_tl_op': 3.3787170479782045,\n",
      " 'mo_sin_rcnt_tl': 95.04201774344736,\n",
      " 'mort_acc': 1296.5820342785494,\n",
      " 'mths_since_last_delinq': 0.0,\n",
      " 'mths_since_last_major_derog': 1238193181.3860199,\n",
      " 'mths_since_last_record': 0.0,\n",
      " 'mths_since_rcnt_il': 73.454835491483692,\n",
      " 'mths_since_recent_bc': 0.15325482443476088,\n",
      " 'mths_since_recent_bc_dlq': 0.19497452919058034,\n",
      " 'mths_since_recent_inq': 34131536458.026405,\n",
      " 'mths_since_recent_revol_delinq': 2642706564.0137477,\n",
      " 'next_pymnt_d': 6.8823245957219132,\n",
      " 'num_accts_ever_120_pd': 537851076.15765619,\n",
      " 'num_actv_bc_tl': 2130412794.1135411,\n",
      " 'num_actv_rev_tl': 457320739.40499395,\n",
      " 'num_bc_sats': 0.92949534424906743,\n",
      " 'num_bc_tl': 3.0773250754787678,\n",
      " 'num_il_tl': 40.183706119533433,\n",
      " 'num_op_rev_tl': 574.07621349874876,\n",
      " 'num_rev_accts': 11.156404169317335,\n",
      " 'num_rev_tl_bal_gt_0': 59.641990041111669,\n",
      " 'num_sats': 0.049192908471540168,\n",
      " 'num_tl_120dpd_2m': 0.1083259667253549,\n",
      " 'num_tl_30dpd': 546.50407338630396,\n",
      " 'open_acc': 8849986.9165603388,\n",
      " 'open_acc_6m': 554613.88339687639,\n",
      " 'open_il_12m': 9631.2067169360125,\n",
      " 'open_il_24m': 298.35346442137279,\n",
      " 'open_il_6m': 2901.1017799645765,\n",
      " 'open_rv_12m': 507.18279492546515,\n",
      " 'open_rv_24m': 35.543684082356194,\n",
      " 'out_prncp': 0.005680206645702816,\n",
      " 'out_prncp_inv': 3862995.3051536209,\n",
      " 'policy_code': 2.1345846070946393,\n",
      " 'pub_rec': 0.026896946695025788,\n",
      " 'purpose': 139.87619886807067,\n",
      " 'pymnt_plan': 588.57231551857092,\n",
      " 'recoveries': 629.06635863509177,\n",
      " 'revol_bal': 504.4861883839605,\n",
      " 'revol_util': 0.0,\n",
      " 'sub_grade': 0.92552641184008455,\n",
      " 'term': 26.59677360092477,\n",
      " 'title': 86047577.891381875,\n",
      " 'tot_coll_amt': 802.96912393603918,\n",
      " 'tot_cur_bal': 0.011077142560204006,\n",
      " 'total_acc': 2847536277.2160163,\n",
      " 'total_bal_il': 3.0487552270821854,\n",
      " 'total_cu_tl': 9.5867368161710012,\n",
      " 'total_pymnt': 27147326865.731583,\n",
      " 'total_pymnt_inv': 1.1885290605600822,\n",
      " 'total_rec_int': 0.70030533342999735,\n",
      " 'total_rec_late_fee': 2.283289093215124,\n",
      " 'total_rec_prncp': 9.6355619737438278,\n",
      " 'total_rev_hi_lim': 5.5129763057765375,\n",
      " 'verification_status': 33.371920939296892,\n",
      " 'verification_status_joint': 270908603.34042257,\n",
      " 'zip_code': 86002145.266162559}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print('Shape: (%d, %d)' %df.iloc[:,:].shape)\n",
    "print('Variation:')\n",
    "pprint.pprint(dict(zip(df.columns, np.var(df.iloc[:,:], 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'N'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1bb5b64bd05c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mth1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVarianceThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mselect1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/env_dsa/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/env_dsa/lib/python3.6/site-packages/sklearn/feature_selection/variance_threshold.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/env_dsa/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'N'"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_selection as fs\n",
    "th1 = np.logspace(0,2,num=3, endpoint=True)\n",
    "select = []\n",
    "for i in th1:\n",
    "    vt = fs.VarianceThreshold(threshold=i)\n",
    "    select1 = vt.fit_transform(df.loc[:,:])\n",
    "    select.append(select1.shape)\n",
    "print(np.array(select))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see by running above script that we can not directly use this here. We need to do some cleaning or some other approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. univariate selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is a regression problem, I will use f_regression for SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105451, 118)\n",
      "(105451,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'N'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6cd4b19df415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbest2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/env_dsa/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/env_dsa/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \"\"\"\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/env_dsa/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    541\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda/envs/env_dsa/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'N'"
     ]
    }
   ],
   "source": [
    "X = np.array(df.iloc[:,:])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "best2 = fs.SelectKBest(fs.f_regression, k=80).fit_transform(X,y)\n",
    "best2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we learned above approach will also not going to work, untill we clean the data. S, lets first do that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac = len(df) * 0.8\n",
    "df.dropna(thresh=frac, axis=1)\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see above, we have tried to drop all the columns that has not more than 70% of the total values as non-na. but non of them has got dropped. Lets try some other approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105451 entries, 0 to 105450\n",
      "Columns: 119 entries, loan_amnt to hardship_flag\n",
      "dtypes: float64(44), int64(54), object(21)\n",
      "memory usage: 95.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try to convert all the 'Object' data type columns into numeric values. This is helpful for our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>application_type</th>\n",
       "      <th>verification_status_joint</th>\n",
       "      <th>sec_app_earliest_cr_line</th>\n",
       "      <th>hardship_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>021xx</td>\n",
       "      <td>MA</td>\n",
       "      <td>w</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>Sep-2017</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>070xx</td>\n",
       "      <td>NJ</td>\n",
       "      <td>w</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>Sep-2017</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198xx</td>\n",
       "      <td>DE</td>\n",
       "      <td>w</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>Sep-2017</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>950xx</td>\n",
       "      <td>CA</td>\n",
       "      <td>w</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>Sep-2017</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>880xx</td>\n",
       "      <td>NM</td>\n",
       "      <td>w</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>Sep-2017</td>\n",
       "      <td>Aug-2017</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code addr_state initial_list_status last_pymnt_d next_pymnt_d  \\\n",
       "0    021xx         MA                   w     Aug-2017     Sep-2017   \n",
       "1    070xx         NJ                   w     Aug-2017     Sep-2017   \n",
       "2    198xx         DE                   w     Aug-2017     Sep-2017   \n",
       "3    950xx         CA                   w     Aug-2017     Sep-2017   \n",
       "4    880xx         NM                   w     Aug-2017     Sep-2017   \n",
       "\n",
       "  last_credit_pull_d application_type verification_status_joint  \\\n",
       "0           Aug-2017       INDIVIDUAL                       NaN   \n",
       "1           Aug-2017       INDIVIDUAL                       NaN   \n",
       "2           Aug-2017       INDIVIDUAL                       NaN   \n",
       "3           Aug-2017       INDIVIDUAL                       NaN   \n",
       "4           Aug-2017       INDIVIDUAL                       NaN   \n",
       "\n",
       "  sec_app_earliest_cr_line hardship_flag  \n",
       "0                      NaN             N  \n",
       "1                      NaN             N  \n",
       "2                      NaN             N  \n",
       "3                      NaN             N  \n",
       "4                      NaN             N  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=['object']).iloc[0:5,11:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am droping all below listed columns because we dont need these columns inorder to determine int_rate as our result. This means we have already approved a loan_amnt and based on loan_amnt and other credit details we can determine int_rate.\n",
    "- issue_d, last_pymnt_d, next_payment_d, 'last_credit_pull_d' is not relevant for loan int_rate. \n",
    "- title and purpose are almost same, but title has some text value while purpose is like selected field values. Still dropping both as not relevant.\n",
    "- zip_code is not complete value (means it suffix with 'xx'). lets drop it.\n",
    "- initial_list_status, hardship_flag not clear.\n",
    "- df.drop(['last_credit_pull_d'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df.drop(['grade','sub_grade','emp_title', 'issue_d', 'loan_status','pymnt_plan','title', 'purpose', 'zip_code',\n",
    "         'initial_list_status','last_pymnt_d','next_pymnt_d','last_credit_pull_d','hardship_flag'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 36 months    77105\n",
       " 60 months    28346\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajsomani/anaconda/envs/env_dsa/lib/python3.6/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 36    77105\n",
       " 60    28346\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.term = df.term.str.replace(' months', '')\n",
    "df.term = df.term.astype(int)\n",
    "df.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>application_type</th>\n",
       "      <th>verification_status_joint</th>\n",
       "      <th>sec_app_earliest_cr_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>MA</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>NJ</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OWN</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>DE</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Verified</td>\n",
       "      <td>CA</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OWN</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>NM</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  home_ownership verification_status addr_state application_type  \\\n",
       "0       MORTGAGE        Not Verified         MA       INDIVIDUAL   \n",
       "1           RENT            Verified         NJ       INDIVIDUAL   \n",
       "2            OWN        Not Verified         DE       INDIVIDUAL   \n",
       "3       MORTGAGE            Verified         CA       INDIVIDUAL   \n",
       "4            OWN        Not Verified         NM       INDIVIDUAL   \n",
       "\n",
       "  verification_status_joint sec_app_earliest_cr_line  \n",
       "0                       NaN                      NaN  \n",
       "1                       NaN                      NaN  \n",
       "2                       NaN                      NaN  \n",
       "3                       NaN                      NaN  \n",
       "4                       NaN                      NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=['object']).iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Verified       2425\n",
       "Source Verified    2346\n",
       "Verified           2042\n",
       "Name: verification_status_joint, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.verification_status_joint.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98638"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.verification_status_joint.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.verification_status_joint\n",
    "test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I want to convert all categorical columns to interger but not getting how. I can use OneHotEncoder but still facing some issues. Will work on it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
